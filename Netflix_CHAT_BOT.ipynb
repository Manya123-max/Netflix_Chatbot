{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo3Pw9WLs0xiPHu5n0WkLQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manya123-max/Netflix_Chatbot/blob/main/Netflix_CHAT_BOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZhVotEwyrRa",
        "outputId": "09b7ae6a-e747-4fa8-e42a-fc2435b25f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dtBtllJqvdmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data (run this once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dose1CcmvfY5",
        "outputId": "fefaebdc-cc3d-4936-c491-5378996e2f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "def load_dataset():\n",
        "    \"\"\"\n",
        "    Load the Netflix dataset containing titles, genres, release years, and descriptions.\n",
        "    \"\"\"\n",
        "    # Replace 'netflix_dataset.csv' with your actual dataset file path\n",
        "    df = pd.read_csv('/content/netflix_titles.csv', encoding='latin-1')\n",
        "    return df"
      ],
      "metadata": {
        "id": "4nnTZ8O3vhaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing steps\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset:\n",
        "    1. Lowercase text.\n",
        "    2. Tokenize.\n",
        "    3. Remove stopwords.\n",
        "    4. Perform stemming.\n",
        "    \"\"\"\n",
        "    ps = PorterStemmer()\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "    def preprocess_text(text):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "        # Remove stopwords and apply stemming\n",
        "        tokens = [ps.stem(word) for word in tokens if word.isalnum() and word not in stopwords]\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "    df['Processed_Description'] = df['description'].apply(preprocess_text)\n",
        "    return df"
      ],
      "metadata": {
        "id": "UNoWveiRvkTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Bag of Words (BOW)\n",
        "def create_bow(df):\n",
        "    \"\"\"\n",
        "    Create a Bag of Words (BOW) representation for the processed descriptions.\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer()\n",
        "    bow_matrix = vectorizer.fit_transform(df['Processed_Description'])\n",
        "    return vectorizer, bow_matrix"
      ],
      "metadata": {
        "id": "DDwQZXqlvoRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform one-hot encoding for genres\n",
        "def one_hot_encode_genres(df):\n",
        "    \"\"\"\n",
        "    Perform one-hot encoding on the 'Genre' column.\n",
        "    \"\"\"\n",
        "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # handle_unknown='ignore' to avoid errors if a new genre appears in user input.\n",
        "    # Changed 'Genre' to 'listed_in' as that is the actual column name for genres\n",
        "    genre_matrix = encoder.fit_transform(df[['listed_in']])\n",
        "    genre_labels = encoder.categories_[0]\n",
        "    return encoder, genre_matrix, genre_labels"
      ],
      "metadata": {
        "id": "zKBK0xdqvsBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best match using cosine similarity\n",
        "def find_match(user_input, df, vectorizer, bow_matrix):\n",
        "    \"\"\"\n",
        "    Find the best matching title or description using cosine similarity.\n",
        "    \"\"\"\n",
        "    ps = PorterStemmer()\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "    # Preprocess user input\n",
        "    tokens = word_tokenize(user_input.lower())\n",
        "    processed_input = \" \".join([ps.stem(word) for word in tokens if word.isalnum() and word not in stopwords])\n",
        "\n",
        "    # Transform user input into BOW vector\n",
        "    user_vector = vectorizer.transform([processed_input])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    similarity_scores = cosine_similarity(user_vector, bow_matrix)\n",
        "    best_match_index = np.argmax(similarity_scores)\n",
        "    best_score = similarity_scores[0, best_match_index]\n",
        "\n",
        "    if best_score > 0.1:  # Adjust threshold as needed\n",
        "        return df.iloc[best_match_index]\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "Cl7ncDZ-3jGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot logic\n",
        "def netflix_chatbot():\n",
        "    \"\"\"\n",
        "    Main function for Netflix chatbot interaction.\n",
        "    \"\"\"\n",
        "    # Load and preprocess dataset\n",
        "    df = load_dataset()\n",
        "    df = preprocess_data(df)\n",
        "    vectorizer, bow_matrix = create_bow(df)\n",
        "    encoder, genre_matrix, genre_labels = one_hot_encode_genres(df)\n",
        "\n",
        "    print(\"Netflix Chatbot: Hi! I can help you find movies or TV shows. Ask me anything!\")\n",
        "    print(\"Type 'exit' to end the conversation.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()  # Remove any surrounding whitespace\n",
        "\n",
        "        # Check for exit command\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Netflix Chatbot: Goodbye! Enjoy your streaming!\")\n",
        "            break\n",
        "\n",
        "        # Find best match for user input\n",
        "        match = find_match(user_input, df, vectorizer, bow_matrix)\n",
        "\n",
        "        if match is not None:\n",
        "            response = (\n",
        "                f\"I found something for you!\\n\"\n",
        "                f\"Title: {match['title']}\\n\"\n",
        "                f\"Genre: {match['listed_in']}\\n\"\n",
        "                f\"Release Year: {match['release_year']}\\n\"\n",
        "                f\"Description: {match['description']}\"\n",
        "            )\n",
        "        else:\n",
        "            response = \"I'm sorry, I couldn't find anything matching your query. Please try again with a different question.\"\n",
        "\n",
        "        print(f\"Netflix Chatbot: {response}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    netflix_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhKnIYx0v2iR",
        "outputId": "fa24f210-09d5-45fd-aae6-88f4b9650ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Netflix Chatbot: Hi! I can help you find movies or TV shows. Ask me anything!\n",
            "Type 'exit' to end the conversation.\n",
            "\n",
            "You: goa\n",
            "Netflix Chatbot: I found something for you!\n",
            "Title: Honeymoon Travels Pvt. Ltd.\n",
            "Genre: Comedies, Dramas, International Movies\n",
            "Release Year: 2007\n",
            "Description: This offbeat comedy-drama follows six quirky newlywed couples as they set off on a bus from Mumbai to Goa on their honeymoons.\n",
            "\n",
            "You: amaran\n",
            "Netflix Chatbot: I'm sorry, I couldn't find anything matching your query. Please try again with a different question.\n",
            "\n",
            "You: horror movie \n",
            "Netflix Chatbot: I found something for you!\n",
            "Title: Scream 3\n",
            "Genre: Horror Movies\n",
            "Release Year: 2000\n",
            "Description: This installment of the tongue-in-cheek horror franchise finds Sidney Prescott once again battling a crazed killer â this time, on a movie set.\n",
            "\n",
            "You: comdy movie \n",
            "Netflix Chatbot: I found something for you!\n",
            "Title: A Scandall\n",
            "Genre: International Movies, Thrillers\n",
            "Release Year: 2016\n",
            "Description: A film school graduate is interested in making a movie about his girlfriend's uncle, who claims that he can see his long-dead daughter.\n",
            "\n",
            "You: stranger things \n",
            "Netflix Chatbot: I found something for you!\n",
            "Title: Beyond Stranger Things\n",
            "Genre: Stand-Up Comedy & Talk Shows, TV Mysteries, TV Sci-Fi & Fantasy\n",
            "Release Year: 2017\n",
            "Description: Secrets from the \"Stranger Things 2\" universe are revealed as cast and guests discuss the latest episodes with host Jim Rash. Caution: spoilers ahead!\n",
            "\n",
            "You: exit\n",
            "Netflix Chatbot: Goodbye! Enjoy your streaming!\n"
          ]
        }
      ]
    }
  ]
}